# An치lisis de Optimizaciones para xml-domloader.py

## 游댌 Optimizaciones Identificadas

### 1. **Paralelizaci칩n de Embeddings (CR칈TICO - Alto Impacto)**

**Problema**: En `qdrant_upsert_document()` (l칤neas 499-518), los embeddings se procesan secuencialmente. Esto es muy lento cuando hay muchas unidades.

**Impacto**: Si un documento tiene 50 unidades, y cada embedding tarda 100ms, el total es 5 segundos. Con paralelizaci칩n (p.ej. 10 concurrentes), ser칤a ~500ms.

**Soluci칩n**: Usar `asyncio.gather()` para procesar embeddings en paralelo con un sem치foro para limitar concurrencia.

```python
# En lugar de:
for u in doc.units[1:]:
    vec = await embedder.embed(u["text"])
    # ...

# Usar:
async def embed_unit(u):
    vec = await embedder.embed(u["text"])
    return u, vec

# Con sem치foro para limitar concurrencia de embeddings
embed_sem = asyncio.Semaphore(10)  # Ajustar seg칰n recursos
tasks = [embed_unit(u) for u in doc.units[1:]]
results = await asyncio.gather(*tasks)
```

---

### 2. **Batching de Operaciones Neo4j (ALTO IMPACTO)**

**Problema**: En `neo4j_upsert_document()` (l칤neas 568-588), cada unidad se inserta con una query separada. Esto genera mucha latencia de red.

**Impacto**: 50 unidades = 50 queries = ~2-5 segundos (dependiendo de latencia). Con batching = 1 query = ~50-100ms.

**Soluci칩n**: Usar UNWIND de Cypher para insertar m칰ltiples unidades en una sola query:

```python
# En lugar de:
for u in doc.units:
    await s.run("MERGE...", {...})

# Usar:
units_data = [{"key": f"{doc.doc_id}::{u['unit_id']}", ...} for u in doc.units]
await s.run("""
    MATCH (d:Document {doc_id: $doc_id})
    UNWIND $units AS unit
    MERGE (u:Unit {key: unit.key})
    SET u.unit_id = unit.unit_id, ...
    MERGE (d)-[:CONTAINS]->(u)
""", {"doc_id": doc.doc_id, "units": units_data})
```

---

### 3. **Optimizaci칩n de XPath con translate() (MEDIO IMPACTO)**

**Problema**: Las expresiones XPath usan `translate()` repetidamente, lo cual es costoso. Adem치s, se construyen strings XPath largos en cada llamada.

**Impacto**: En documentos grandes con muchas unidades, las queries XPath se ejecutan muchas veces.

**Soluci칩n**: 
- Pre-compilar namespaces normalizados
- Cachear expresiones XPath comunes
- Usar funciones auxiliares para normalizar nombres una vez

```python
# Cachear expresiones comunes
_NORMALIZE_NS = str.maketrans('츼칄칈칍칔칖칌', 'AEIOUUN')
def normalize_tag(tag: str) -> str:
    return tag.translate(_NORMALIZE_NS)

# Pre-compilar XPath cuando sea posible
```

---

### 4. **Hash Calculations Repetidas (BAJO-MEDIO IMPACTO)**

**Problema**: Se calculan hashes SHA1/SHA256 m칰ltiples veces para el mismo contenido (p.ej. en `normalize_doc_id` y en `qdrant_upsert_document`).

**Soluci칩n**: Cachear hashes calculados o calcular una vez y reutilizar.

---

### 5. **File I/O S칤ncrono en Contexto Async (MEDIO IMPACTO)**

**Problema**: `load_meta()`, `save_meta()`, `save_xml()` usan I/O s칤ncrono dentro de funciones async. Esto bloquea el event loop.

**Impacto**: Con alta concurrencia, puede crear cuellos de botella.

**Soluci칩n**: Usar `aiofiles` para I/O as칤ncrono:

```python
import aiofiles
import aiofiles.os

async def load_meta(doc_id: str) -> StoredMeta:
    mp = meta_path(doc_id)
    if not await aiofiles.os.path.exists(mp):
        return StoredMeta()
    async with aiofiles.open(mp, "r", encoding="utf-8") as f:
        content = await f.read()
        d = json.loads(content)
        return StoredMeta(...)
```

---

### 6. **Memory Usage para XML Grandes (BAJO IMPACTO - Solo si hay archivos >100MB)**

**Problema**: XML completo se carga en memoria (`await r.read()`). Para archivos muy grandes (>100MB), esto puede ser problem치tico.

**Soluci칩n**: Streaming parsing solo si es necesario. Para BOE probablemente no hace falta, pero puede considerarse.

---

### 7. **Error Handling Mejorado (CALIDAD DE C칍DIGO)**

**Problema**: Faltan try/except en operaciones cr칤ticas (embeddings, Neo4j, Qdrant).

**Soluci칩n**: A침adir manejo de errores con logging y retry logic donde sea apropiado.

---

### 8. **Optimizaci칩n de Construcci칩n de Payloads (BAJO IMPACTO)**

**Problema**: En `qdrant_upsert_document()`, el payload se construye repetidamente con el mismo c칩digo para cada unidad.

**Soluci칩n**: Funci칩n auxiliar para construir payloads:

```python
def _build_unit_payload(doc: ParsedDocument, unit: Dict[str, Any]) -> Dict[str, Any]:
    return {
        "doc_id": doc.doc_id,
        "boe_id": doc.boe_id,
        "eli_uri": doc.eli_uri,
        "title": doc.title,
        "source_url": doc.source_url,
        "unit_id": unit["unit_id"],
        "label": unit["label"],
        "path": unit["path"],
        "text": unit["text"],
        **{k: v for k, v in doc.dates.items() if v},
    }
```

---

### 9. **Connection Pooling y Reutilizaci칩n (BAJO IMPACTO)**

**Problema**: El driver de Neo4j se cierra y abre. Con m칰ltiples ejecuciones, podr칤a mantenerse abierto.

**Soluci칩n**: Ya est치 bien manejado, pero podr칤a considerarse un contexto manager global si hay m칰ltiples ejecuciones.

---

### 10. **Pre-computaci칩n de Paths XML (MUY BAJO IMPACTO)**

**Problema**: `root.getroottree().getpath(el)` se llama para cada unidad. Es relativamente costoso.

**Soluci칩n**: Solo llamar si realmente se necesita. Para muchos casos, el unit_id podr칤a ser suficiente.

---

## 游늵 Priorizaci칩n de Implementaci칩n

1. **游댮 CR칈TICO**: Paralelizaci칩n de embeddings (#1)
2. **游 ALTO**: Batching de Neo4j (#2)
3. **游리 MEDIO**: XPath optimization (#3), File I/O async (#5)
4. **游릭 BAJO**: Resto de optimizaciones

## 游눠 Estimaci칩n de Mejora

Con las optimizaciones #1 y #2 implementadas:
- **Embeddings**: De N칑100ms a (N/10)칑100ms = **~10x m치s r치pido**
- **Neo4j**: De N칑50ms a 1칑100ms = **~50x m치s r치pido** (para 50 unidades)
- **Total**: Mejora estimada de **3-5x** en documentos con muchas unidades

